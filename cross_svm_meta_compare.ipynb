{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b056dd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "TRAIN: CICIDS2017  →  TEST: CICIDS2018\n",
      "========================================\n",
      "Train shape after sampling: (200000, 53)\n",
      "Test shape after sampling:  (200000, 80)\n",
      "Common feature count (before removing meta): 52\n",
      "\n",
      "--- WITH META ---\n",
      "Feature count (WITH META): 52\n",
      "\n",
      "[WITH META] Confusion Matrix:\n",
      "[[149498  21360]\n",
      " [ 26520   2622]]\n",
      "\n",
      "[WITH META] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8493    0.8750    0.8620    170858\n",
      "           1     0.1093    0.0900    0.0987     29142\n",
      "\n",
      "    accuracy                         0.7606    200000\n",
      "   macro avg     0.4793    0.4825    0.4803    200000\n",
      "weighted avg     0.7415    0.7606    0.7508    200000\n",
      "\n",
      "\n",
      "--- NO META ---\n",
      "Feature count (NO META): 40\n",
      "\n",
      "[NO META] Confusion Matrix:\n",
      "[[142959  27899]\n",
      " [ 26252   2890]]\n",
      "\n",
      "[NO META] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8449    0.8367    0.8408    170858\n",
      "           1     0.0939    0.0992    0.0964     29142\n",
      "\n",
      "    accuracy                         0.7292    200000\n",
      "   macro avg     0.4694    0.4679    0.4686    200000\n",
      "weighted avg     0.7354    0.7292    0.7323    200000\n",
      "\n",
      "\n",
      "========================================\n",
      "END: TRAIN CICIDS2017  →  TEST CICIDS2018\n",
      "========================================\n",
      "\n",
      "\n",
      "========================================\n",
      "TRAIN: CICIDS2017  →  TEST: CICDDoS2019\n",
      "========================================\n",
      "Train shape after sampling: (200000, 53)\n",
      "Test shape after sampling:  (200000, 78)\n",
      "Common feature count (before removing meta): 51\n",
      "\n",
      "--- WITH META ---\n",
      "Feature count (WITH META): 51\n",
      "\n",
      "[WITH META] Confusion Matrix:\n",
      "[[ 44452    962]\n",
      " [139114  15472]]\n",
      "\n",
      "[WITH META] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2422    0.9788    0.3883     45414\n",
      "           1     0.9415    0.1001    0.1809    154586\n",
      "\n",
      "    accuracy                         0.2996    200000\n",
      "   macro avg     0.5918    0.5395    0.2846    200000\n",
      "weighted avg     0.7827    0.2996    0.2280    200000\n",
      "\n",
      "\n",
      "--- NO META ---\n",
      "Feature count (NO META): 40\n",
      "\n",
      "[NO META] Confusion Matrix:\n",
      "[[ 44239   1175]\n",
      " [142844  11742]]\n",
      "\n",
      "[NO META] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2365    0.9741    0.3806     45414\n",
      "           1     0.9090    0.0760    0.1402    154586\n",
      "\n",
      "    accuracy                         0.2799    200000\n",
      "   macro avg     0.5728    0.5250    0.2604    200000\n",
      "weighted avg     0.7563    0.2799    0.1948    200000\n",
      "\n",
      "\n",
      "========================================\n",
      "END: TRAIN CICIDS2017  →  TEST CICDDoS2019\n",
      "========================================\n",
      "\n",
      "\n",
      "========================================\n",
      "TRAIN: CICIDS2018  →  TEST: CICIDS2017\n",
      "========================================\n",
      "Train shape after sampling: (200000, 80)\n",
      "Test shape after sampling:  (200000, 53)\n",
      "Common feature count (before removing meta): 52\n",
      "\n",
      "--- WITH META ---\n",
      "Feature count (WITH META): 52\n",
      "\n",
      "[WITH META] Confusion Matrix:\n",
      "[[ 48425 117697]\n",
      " [  2667  31211]]\n",
      "\n",
      "[WITH META] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9478    0.2915    0.4459    166122\n",
      "           1     0.2096    0.9213    0.3415     33878\n",
      "\n",
      "    accuracy                         0.3982    200000\n",
      "   macro avg     0.5787    0.6064    0.3937    200000\n",
      "weighted avg     0.8228    0.3982    0.4282    200000\n",
      "\n",
      "\n",
      "--- NO META ---\n",
      "Feature count (NO META): 40\n",
      "\n",
      "[NO META] Confusion Matrix:\n",
      "[[97040 69082]\n",
      " [ 1891 31987]]\n",
      "\n",
      "[NO META] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9809    0.5841    0.7322    166122\n",
      "           1     0.3165    0.9442    0.4741     33878\n",
      "\n",
      "    accuracy                         0.6451    200000\n",
      "   macro avg     0.6487    0.7642    0.6031    200000\n",
      "weighted avg     0.8683    0.6451    0.6885    200000\n",
      "\n",
      "\n",
      "========================================\n",
      "END: TRAIN CICIDS2018  →  TEST CICIDS2017\n",
      "========================================\n",
      "\n",
      "\n",
      "========================================\n",
      "TRAIN: CICIDS2018  →  TEST: CICDDoS2019\n",
      "========================================\n",
      "Train shape after sampling: (200000, 80)\n",
      "Test shape after sampling:  (200000, 78)\n",
      "Common feature count (before removing meta): 69\n",
      "\n",
      "--- WITH META ---\n",
      "Feature count (WITH META): 69\n",
      "\n",
      "[WITH META] Confusion Matrix:\n",
      "[[15224 30190]\n",
      " [83648 70938]]\n",
      "\n",
      "[WITH META] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.1540    0.3352    0.2110     45414\n",
      "           1     0.7015    0.4589    0.5548    154586\n",
      "\n",
      "    accuracy                         0.4308    200000\n",
      "   macro avg     0.4277    0.3971    0.3829    200000\n",
      "weighted avg     0.5771    0.4308    0.4768    200000\n",
      "\n",
      "\n",
      "--- NO META ---\n",
      "Feature count (NO META): 58\n",
      "\n",
      "[NO META] Confusion Matrix:\n",
      "[[30737 14677]\n",
      " [78941 75645]]\n",
      "\n",
      "[NO META] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2802    0.6768    0.3964     45414\n",
      "           1     0.8375    0.4893    0.6177    154586\n",
      "\n",
      "    accuracy                         0.5319    200000\n",
      "   macro avg     0.5589    0.5831    0.5071    200000\n",
      "weighted avg     0.7110    0.5319    0.5675    200000\n",
      "\n",
      "\n",
      "========================================\n",
      "END: TRAIN CICIDS2018  →  TEST CICDDoS2019\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# ============================================\n",
    "# CONFIG: META COLUMNS (SAME ACROSS DATASETS)\n",
    "# ============================================\n",
    "META_COLS = [\n",
    "    \"Dst Port\",\n",
    "    \"Init Fwd Win Byts\",\n",
    "    \"Init Bwd Win Byts\",\n",
    "    \"Fwd Act Data Pkts\",\n",
    "    \"Fwd Seg Size Min\",\n",
    "    \"Subflow Fwd Byts\",\n",
    "    \"Active Mean\", \"Active Max\", \"Active Min\",\n",
    "    \"Idle Mean\", \"Idle Max\", \"Idle Min\"\n",
    "]\n",
    "\n",
    "# ============================================\n",
    "# HELPER: BUILD SVM PIPELINE\n",
    "# ============================================\n",
    "def build_svm():\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svm\", LinearSVC(\n",
    "            class_weight=\"balanced\",\n",
    "            max_iter=5000\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "# ============================================\n",
    "# HELPER: RUN ONE CROSS-DATASET EXPERIMENT\n",
    "# ============================================\n",
    "def run_cross_svm(\n",
    "    train_file,\n",
    "    test_file,\n",
    "    train_name,\n",
    "    test_name,\n",
    "    sample_train=200000,\n",
    "    sample_test=200000,\n",
    "    label_col=\"Label\"\n",
    "):\n",
    "    print(\"\\n========================================\")\n",
    "    print(f\"TRAIN: {train_name}  →  TEST: {test_name}\")\n",
    "    print(\"========================================\")\n",
    "\n",
    "    # ---------- LOAD ----------\n",
    "    train_df = pd.read_csv(train_file)\n",
    "    test_df  = pd.read_csv(test_file)\n",
    "\n",
    "    # Optional sampling for speed\n",
    "    if sample_train is not None and len(train_df) > sample_train:\n",
    "        train_df = train_df.sample(sample_train, random_state=42)\n",
    "    if sample_test is not None and len(test_df) > sample_test:\n",
    "        test_df = test_df.sample(sample_test, random_state=42)\n",
    "\n",
    "    print(f\"Train shape after sampling: {train_df.shape}\")\n",
    "    print(f\"Test shape after sampling:  {test_df.shape}\")\n",
    "\n",
    "    # ---------- SPLIT FEATURES / LABEL ----------\n",
    "    X_train_full = train_df.drop(columns=[label_col])\n",
    "    y_train = train_df[label_col]\n",
    "\n",
    "    X_test_full = test_df.drop(columns=[label_col])\n",
    "    y_test = test_df[label_col]\n",
    "\n",
    "    # ---------- ALIGN COLUMNS (IMPORTANT!) ----------\n",
    "    # use only columns shared by both datasets\n",
    "    common_cols = sorted(list(set(X_train_full.columns) & set(X_test_full.columns)))\n",
    "    X_train_full = X_train_full[common_cols]\n",
    "    X_test_full  = X_test_full[common_cols]\n",
    "\n",
    "    print(f\"Common feature count (before removing meta): {len(common_cols)}\")\n",
    "\n",
    "    # ---------- WITH META ----------\n",
    "    X_train_meta = X_train_full.copy()\n",
    "    X_test_meta  = X_test_full.copy()\n",
    "\n",
    "    print(\"\\n--- WITH META ---\")\n",
    "    print(f\"Feature count (WITH META): {X_train_meta.shape[1]}\")\n",
    "\n",
    "    svm_meta = build_svm()\n",
    "    svm_meta.fit(X_train_meta, y_train)\n",
    "    pred_meta = svm_meta.predict(X_test_meta)\n",
    "\n",
    "    print(\"\\n[WITH META] Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, pred_meta))\n",
    "    print(\"\\n[WITH META] Classification Report:\")\n",
    "    print(classification_report(y_test, pred_meta, digits=4))\n",
    "\n",
    "    # ---------- NO META ----------\n",
    "    # drop meta columns if present, then re-align in case some meta cols were missing\n",
    "    X_train_nometa = X_train_full.drop(columns=META_COLS, errors=\"ignore\")\n",
    "    X_test_nometa  = X_test_full.drop(columns=META_COLS, errors=\"ignore\")\n",
    "\n",
    "    # ensure same order and intersection again\n",
    "    common_nometa = sorted(list(set(X_train_nometa.columns) & set(X_test_nometa.columns)))\n",
    "    X_train_nometa = X_train_nometa[common_nometa]\n",
    "    X_test_nometa  = X_test_nometa[common_nometa]\n",
    "\n",
    "    print(\"\\n--- NO META ---\")\n",
    "    print(f\"Feature count (NO META): {X_train_nometa.shape[1]}\")\n",
    "\n",
    "    svm_nometa = build_svm()\n",
    "    svm_nometa.fit(X_train_nometa, y_train)\n",
    "    pred_nometa = svm_nometa.predict(X_test_nometa)\n",
    "\n",
    "    print(\"\\n[NO META] Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, pred_nometa))\n",
    "    print(\"\\n[NO META] Classification Report:\")\n",
    "    print(classification_report(y_test, pred_nometa, digits=4))\n",
    "\n",
    "    print(\"\\n========================================\")\n",
    "    print(f\"END: TRAIN {train_name}  →  TEST {test_name}\")\n",
    "    print(\"========================================\\n\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# RUN ALL FOUR CROSS-TESTS\n",
    "# ============================================\n",
    "TRAIN_2017 = \"CICIDS2017-SVM-ready.csv\"\n",
    "TRAIN_2018 = \"CICIDS2018-SVM-ready.csv\"\n",
    "TEST_2017  = \"CICIDS2017-SVM-ready.csv\"\n",
    "TEST_2018  = \"CICIDS2018-SVM-ready.csv\"\n",
    "TEST_2019  = \"CICDDoS2019-SVM-ready.csv\"\n",
    "\n",
    "# 1) Train 2017 → Test 2018\n",
    "run_cross_svm(\n",
    "    train_file=TRAIN_2017,\n",
    "    test_file=TEST_2018,\n",
    "    train_name=\"CICIDS2017\",\n",
    "    test_name=\"CICIDS2018\"\n",
    ")\n",
    "\n",
    "# 2) Train 2017 → Test 2019\n",
    "run_cross_svm(\n",
    "    train_file=TRAIN_2017,\n",
    "    test_file=TEST_2019,\n",
    "    train_name=\"CICIDS2017\",\n",
    "    test_name=\"CICDDoS2019\"\n",
    ")\n",
    "\n",
    "# 3) Train 2018 → Test 2017\n",
    "run_cross_svm(\n",
    "    train_file=TRAIN_2018,\n",
    "    test_file=TEST_2017,\n",
    "    train_name=\"CICIDS2018\",\n",
    "    test_name=\"CICIDS2017\"\n",
    ")\n",
    "\n",
    "# 4) Train 2018 → Test 2019\n",
    "run_cross_svm(\n",
    "    train_file=TRAIN_2018,\n",
    "    test_file=TEST_2019,\n",
    "    train_name=\"CICIDS2018\",\n",
    "    test_name=\"CICDDoS2019\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
